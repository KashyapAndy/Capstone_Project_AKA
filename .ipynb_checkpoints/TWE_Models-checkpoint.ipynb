{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries for this project.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import re\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing all the models directory\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW ALL COLUMNS & ALL TEXT IN EACH CELL\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_review = pd.read_csv('Final_Review.csv', index_col=0)\n",
    "whisky_pd = pd.read_csv('Whisky_EDA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisky_pd.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H/T Dale Wahl/Joe Klien for helping create confusion matrix.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, roc_auc_score\n",
    "\n",
    "def eval_sklearn_model(y_true, predictions, average, model=None, X=None):\n",
    "    \"\"\"This function takes the true values for y and the predictions made by the model and prints out the confusion matrix along with Accuracy, Precision, and, if model and X provided, Roc_Auc Scores.\"\"\"\n",
    "    cnf_matrix = confusion_matrix(y_true, predictions)\n",
    "\n",
    "    print('True Negative: ', cnf_matrix[0, 0], '| False Positive: ', cnf_matrix[0, 1])\n",
    "    print('False Negative: ', cnf_matrix[1, 0], '| True Positive: ', cnf_matrix[1, 1], '\\n')\n",
    "\n",
    "    sensitivity = cnf_matrix[1, 1]/ (cnf_matrix[1, 0] + cnf_matrix[1, 1])\n",
    "    specificity = cnf_matrix[0, 0]/ (cnf_matrix[0, 1] + cnf_matrix[0, 0])\n",
    "\n",
    "    print('Sensitivity (TP/ TP + FN): ', sensitivity)\n",
    "    print('Specificity (TN/ TN + FP): ', specificity, '\\n')\n",
    "\n",
    "    print('Accuracy: ', accuracy_score(y_true, predictions, normalize=True))\n",
    "    print('Precision: ', precision_score(y_true, predictions, average = average))\n",
    "    if model != None:\n",
    "        print('Roc-Auc: ', roc_auc_score(y_true, [x[1] for x in model.predict_proba(X)]))\n",
    "    else:\n",
    "        pass\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## START WITH DROPPING STUFF THAT WONT BE USEFUL IN MODEL BUILDING\n",
    "\n",
    "whisky_pd.drop(['Volume_ml', 'Price_Bottle$', 'WhiskyURL', 'Bottler'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make everything lower case\n",
    "\n",
    "columns = ['WhiskyType', 'Description', 'Distillery', 'Whisky', 'Country', 'Region', 'TasteInfo']\n",
    "for i in columns:\n",
    "    whisky_pd[i] = whisky_pd[i].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR WHISKYTYPE\n",
    "\n",
    "whiskytype = pd.get_dummies(whisky_pd['WhiskyType'], prefix = 'w')\n",
    "whiskytype.drop('w_rest of world whisky', axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR DISTILLERY TYPE\n",
    "\n",
    "distillerytype = pd.get_dummies(whisky_pd['Distillery'], prefix = 'd')\n",
    "distillerytype.drop('d_johnnie walker', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR COUNTRY \n",
    "\n",
    "countrytype = pd.get_dummies(whisky_pd['Country'], prefix = 'c')\n",
    "countrytype.drop('c_japan', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR REGION\n",
    "\n",
    "regiontype = pd.get_dummies(whisky_pd['Region'], prefix = 'r')\n",
    "regiontype.drop('r_kentucky', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR COLOURING. LET US TRY A DIFFERENT WAY\n",
    "\n",
    "whisky_pd['Colouring'].replace(('Yes', 'No'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR STATUS. LET US TRY A DIFFERENT WAY\n",
    "\n",
    "whisky_pd['Status'].replace(('Active', 'Silent'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR AGE_TYPE. LET US TRY A DIFFERENT WAY\n",
    "\n",
    "whisky_pd['AgeType'].replace(('YAS', 'NAS'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR AGE_TYPE. LET US TRY A DIFFERENT WAY\n",
    "\n",
    "whisky_pd['BottlingType'].replace(('Distillery', 'Independent'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR AGE_TYPE. LET US TRY A DIFFERENT WAY\n",
    "\n",
    "whisky_pd['VintageInfo'].replace(('No Vintage', 'Vintage'), (0, 1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR EDITIONS\n",
    "\n",
    "whisky_pd['LimitedEditions'].replace(('No Info', 'Limited'), (0, 1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DUMMIES FOR EDITIONS\n",
    "\n",
    "whisky_pd['CaskInfo'].replace(('No Info', 'SpecialCask'), (0, 1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET A LIST OF FLAVORS HERE. DROP CHARACTER ITEM\n",
    "\n",
    "flavorlist = list(whisky_pd['Character'])\n",
    "flavorlist\n",
    "\n",
    "completeflavors = []\n",
    "for i in flavorlist:\n",
    "    if type(i)==float:\n",
    "        pass\n",
    "    else:\n",
    "        for j in i.split():\n",
    "            j = j.lower().replace('(', '').replace(')', '')\n",
    "            completeflavors.append(j)\n",
    "\n",
    "## REMOVE DUPLICATES\n",
    "completeflavors = list(set(completeflavors))\n",
    "\n",
    "## REMOVE 'CHARACTER'\n",
    "\n",
    "otherflavors = ['peat', 'sherry', 'wine', 'rum', 'citrus', 'bourbon', 'cocoa', 'complex', 'creamy', 'oloroso', 'corn', 'fire', 'herbal', 'sea', 'maple', 'medicinal', 'moonshine', 'nectar', 'organic', 'roasted', 'chocolatey', 'peaty', 'smoky', 'nut', 'brine', 'briny', 'maritime']\n",
    "completeflavors.extend(otherflavors)\n",
    "\n",
    "## Add Character column to Description\n",
    "\n",
    "whisky_pd['Description'] = whisky_pd['Description'] + \" \" + whisky_pd['Character'].fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMOVE COLUMNS\n",
    "\n",
    "whisky_pd.drop(['#Ratings', 'Bottling Date', 'Cask Number', 'Cask Type', 'Chill Filtered', 'Series', \n",
    "                'Location', 'Owner', 'No of Bottles', 'Year closed', 'TasteInfo', 'Character'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [whisky_pd, whiskytype, regiontype, countrytype, distillerytype]\n",
    "\n",
    "whisky_pd = pd.concat(frames, axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisky_pd.drop(['WhiskyType', 'Country', 'Region', 'Distillery'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(description):\n",
    "    print(description)\n",
    "    translator = str.maketrans('', '', string.punctuation)   ### REMOVE PUNCTUATION\n",
    "    descsplit = description.split(\" \")\n",
    "    wordstemmer = SnowballStemmer('english')\n",
    "    finallist = [wordstemmer.stem(word) for word in descsplit] \n",
    "    return(' '.join(finallist))\n",
    "\n",
    "whisky_pd['NewDescription'] = whisky_pd['Description'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGING STOP WORDS LIST HERE. TO INCORPORATE A LOT OF WORDS THAT DO NOT ADD ANY INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining stop words here before we process 'Description'\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "new_stop = stopwords.words('english')\n",
    "\n",
    "## Adding Column Names to stop words because no need for them in the description\n",
    "\n",
    "columnnames = list(whisky_pd.columns)\n",
    "columnnames = [x.lower().split() for x in columnnames]\n",
    "\n",
    "\n",
    "import itertools\n",
    "columnnames = list(itertools.chain.from_iterable(columnnames))\n",
    "\n",
    "new_stop.extend(columnnames)\n",
    "\n",
    "## now stop words contain words from distillery, country, region, numbers (age), years(vintage)\n",
    "\n",
    "units = ['zero', 'one','two','three','four','five','six','seven','eight','nine']\n",
    "teens = ['eleven','twelve','thirteen','fourteen','fifteen','sixteen', \\\n",
    "             'seventeen','eighteen','nineteen']\n",
    "tens = ['ten','twenty','thirty','forty','fifty','sixty','seventy', \\\n",
    "            'eighty','ninety']\n",
    "\n",
    "#syears =  [str(x) for x in range(0,101)]\n",
    "#strvintage =  [str(x) for x in range(1900, 2018)]\n",
    "# svintage =  [str(x) + 's' for x in range(1900, 2018)]\n",
    "# stryears =  [str(x) + 'year' for x in range(0,101)]\n",
    "# syoyears = [str(x) + 'yo' for x in range(0,101)]\n",
    "\n",
    "otherwords = ['year', 'old', 'bottle', 'bottle', 'whisky', 'whiskey', \"'s\", 'bottled', 'distillery', 'character', 'characters', 'please', 'note', 'years']\n",
    "\n",
    "new_stop = new_stop + otherwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_stop = [s.replace(\"d_\", '') for s in new_stop]\n",
    "new_stop = [s.replace(\"r_\", '') for s in new_stop]\n",
    "new_stop = [s.replace(\"c_\", '') for s in new_stop]\n",
    "new_stop = [s.replace(\"w_\", '') for s in new_stop]\n",
    "new_stop = sorted(list(set(new_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## START WITH COUNTVECTORIZER\n",
    "\n",
    "countvec = CountVectorizer(stop_words=new_stop, max_features=2000, ngram_range=(1,1))\n",
    "wordfeatures = countvec.fit_transform(whisky_pd[\"NewDescription\"])\n",
    "\n",
    "descriptions = pd.DataFrame(wordfeatures.todense(),columns=countvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET LIST OF COUNTVECTORIZED COLUMNS\n",
    "\n",
    "cols = descriptions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIST OF MOST FREQUENTLY USED WORDS\n",
    "\n",
    "top_50 = descriptions.transpose().sum(axis = 1).sort_values(0, ascending = False)\n",
    "top_50 = top_50.reset_index()\n",
    "top_50.columns = ['Word', \"Frequency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ARRANGE THEM IN ALPHABETICAL ORDER FOR EASY VIEWING\n",
    "\n",
    "descriptions = descriptions.reindex_axis(sorted(descriptions.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET FLAVOR LIST & RENAME COLUMNS THAT ARE FLAVORS TO F_FLAVOR \n",
    "\n",
    "newflavors = ['f_' + x for x in cols if x in completeflavors]\n",
    "oldflavors = [x for x in cols if x in completeflavors]\n",
    "\n",
    "## GETTING RENAMING DONE HERE\n",
    "\n",
    "columndict = dict(zip(oldflavors, newflavors))\n",
    "descriptions = descriptions.rename(columns = columndict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STARTING WITH BINARY CLASS MODEL FIRST & THEN MOVING TO THE MULTICLASS MODEL LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START WITH MODEL BUILDING HERE GUYS!! FIX WHISKY LATER!! FIX THE MISSING AGES LATER TOO!!\n",
    "\n",
    "Xbin = whisky_pd.drop(['Description', 'Whisky', 'WhiskyAge', 'WhiskyVintage', 'Price_L', 'Class', 'NewDescription'], axis = 1)\n",
    "Xbin = pd.concat([Xbin, descriptions], axis = 1).drop('BinClass', axis = 1)\n",
    "\n",
    "ybin = whisky_pd['BinClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(Xbin, ybin, random_state = 42, test_size = 0.3)\n",
    "\n",
    "print(Xbin_train.shape, Xbin_test.shape)\n",
    "print(ybin_train.shape, ybin_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegression()\n",
    "\n",
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "                'C' : [10 ** i for i in range(-2, 5)]}\n",
    "\n",
    "grid = GridSearchCV(logit, param_grid, cv=3)\n",
    "\n",
    "grid.fit(Xbin_train, ybin_train)\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_logit = grid.best_estimator_\n",
    "\n",
    "model = best_logit.fit(Xbin_train, ybin_train)\n",
    "logit_predictions = best_logit.predict(Xbin_test)\n",
    "\n",
    "score = best_logit.score(Xbin_test, ybin_test)\n",
    "\n",
    "print(\"{} Score: {:0.3}\".format('Logitistic Classifier', score, '\\n'))\n",
    "\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)\n",
    "\n",
    "eval_sklearn_model(ybin_test, logit_predictions,'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelpdbin = pd.DataFrame(model.coef_)\n",
    "modelpdbin.columns = Xbin_train.columns\n",
    "\n",
    "modelpdbin = modelpdbin.transpose()\n",
    "modelpdbin.columns = ['Coefficients']\n",
    "\n",
    "modelpdbin = modelpdbin.sort_values('Coefficients', ascending=False).reset_index()\n",
    "\n",
    "modelpdbin = modelpdbin[~modelpdbin['index'].str.contains('_')]\n",
    "modelpdbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rfbin = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rfbin.fit(Xbin_train, ybin_train)\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators' : [100, 200, 500, 1000],\n",
    "             'max_features' : [10, 50, 100, 500, 1000],\n",
    "             'min_samples_leaf' : [1,5,10,50,100,200,500]}\n",
    "\n",
    "grid = GridSearchCV(rfbin, param_grid, cv=3)\n",
    "\n",
    "grid.fit(Xbin_train, ybin_train)\n",
    "\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "best_rf.fit(Xbin_train, ybin_train)\n",
    "\n",
    "rf_predictions = best_rf.predict(Xbin_test)\n",
    "\n",
    "score = best_rf.score(Xbin_test, ybin_test)\n",
    "\n",
    "print(\"{} Score: {:0.3}\".format('Random Forest Classifier', score, '\\n'))\n",
    "\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BINARY CLAS IMPORTANCES USING RANDOMFOREST\n",
    "\n",
    "importancesbin = pd.concat([pd.DataFrame(Xbin_train.columns),pd.DataFrame(rfbin.feature_importances_)], axis = 1)\n",
    "importancesbin.columns = ['Feature', 'Importance']\n",
    "importancesbin = importancesbin.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MOVING TO THE MULTICLASS MODEL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START WITH MODEL BUILDING HERE GUYS!! FIX WHISKY LATER!! FIX THE MISSING AGES LATER TOO!!\n",
    "\n",
    "X = whisky_pd.drop(['Description', 'Whisky', 'WhiskyAge', 'WhiskyVintage', 'Price_L', 'BinClass', 'NewDescription'], axis = 1)\n",
    "X = pd.concat([X, descriptions], axis = 1).drop('Class', axis = 1)\n",
    "\n",
    "y = whisky_pd['Class'] # THIS HAS 0-1-2-3 as the classes of whisky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logitmulti = LogisticRegression(random_state=42)\n",
    "\n",
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "                'C' : [10 ** i for i in range(-2, 5)],\n",
    "             'class_weight' : [None, 'balanced']}\n",
    "\n",
    "grid = GridSearchCV(logitmulti, param_grid, cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_logit = grid.best_estimator_\n",
    "\n",
    "multimodel = best_logit.fit(X_train, y_train)\n",
    "logit_predictions_multi = best_logit.predict(X_test)\n",
    "\n",
    "score = best_logit.score(X_test, y_test)\n",
    "\n",
    "print(\"{} Score: {:0.3}\".format('Logitistic Classifier', score, '\\n'))\n",
    "\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)\n",
    "\n",
    "eval_sklearn_model(y_test, logit_predictions_multi, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_predictions_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisky_pd.iloc[[141]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpd = pd.DataFrame(multimodel.coef_)\n",
    "modelpd.columns = X_train.columns\n",
    "\n",
    "modelpd.head()\n",
    "\n",
    "modelpd = modelpd.transpose()\n",
    "modelpd.columns = ['Class 0', 'Class 1', 'Class 2', 'Class 3']\n",
    "\n",
    "modelpd = modelpd.sort_values('Class 0', ascending=False).reset_index()\n",
    "modelpd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators' : [100, 200, 500, 1000],\n",
    "             'max_features' : [10, 50, 100, 500, 1000],\n",
    "             'min_samples_leaf' : [1,5,10,50,100,200,500]}\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_results = {'params': list(grid.best_params_.items()), 'score': grid.best_score_}\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = best_rf.predict(X_test)\n",
    "\n",
    "score = best_rf.score(X_test, y_test)\n",
    "\n",
    "print(\"{} Score: {:0.3}\".format('Random Forest Classifier', score, '\\n'))\n",
    "\n",
    "print(grid.best_estimator_, '\\n')\n",
    "print('Best Hyperparameters we tested for', '\\n', best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET FEATURE IMPORTANCES\n",
    "\n",
    "importances = pd.concat([pd.DataFrame(X_train.columns),pd.DataFrame(rf.feature_importances_)], axis = 1)\n",
    "importances.columns = ['Feature', 'Importance']\n",
    "importances = importances.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.style as style\n",
    "style.use('seaborn-poster')\n",
    "style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE OVERALL DISTRIBUTION\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "dist_plot = plt.hist(whisky_pd['Price_L'], bins = 25, linewidth=0.5, edgecolor = 'white')\n",
    "plt.xticks(fontsize = 15) #FONT OF TICKS\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.xlabel('Price/L in \\$', fontsize = 15, weight = 'bold') ### XLABEL\n",
    "plt.ylabel('# of Bottles', fontsize = 15, weight = 'bold')  ### YLABEL\n",
    "plt.text(x=0, y=2800, s = 'The distribution of whisky prices on TWE', fontsize = 20, weight = 'bold') ## TOP HEADER\n",
    "plt.text(x=0, y=2550, s = 'Whisky prices range from under \\$50 for everyday bottles to\\n more than \\$50000 for rare collectible bottles from closed stills', fontsize = 15)\n",
    "plt.axhline(y = 2, color = 'black', linewidth = 3, alpha = .7)\n",
    "plt.text(x=-8000, y=-500, s = '     Data Source : The WhiskyExchange | Anirudh Kashyap', fontsize = 12, color = 'black') \n",
    "plt.text(x = -8000, y = -350,\n",
    "    s = '_______________________________________________________________________________________',\n",
    "    color = 'black', alpha = .7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discusclass =list(whisky_pd['Class'].value_counts().keys())\n",
    "discusvalues = list(whisky_pd['Class'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE CLASSIFICATION DISTRIBUTION\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "boxplot = plt.bar(discusclass, discusvalues, width = 0.4, align = 'center')\n",
    "plt.xlabel('Price/L in \\$', fontsize = 15, weight = 'bold')\n",
    "plt.ylabel('# of Bottles', fontsize = 15, weight = 'bold')\n",
    "plt.xticks(discusclass)\n",
    "plt.axhline(y = 5, color = 'black', linewidth = 3, alpha = .7)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.text(x=-0.5, y=1300, s = 'Categorizing Whisky prices using DiSCUS\\nclassification', fontsize = 20, weight = 'bold')\n",
    "plt.text(x=-0.3, y=500, s = 'under $50', fontsize = 15)\n",
    "plt.text(x=0.5, y=700, s = 'more than $50\\nless than $100', fontsize = 15)\n",
    "plt.text(x=1.50, y=1200, s = 'more than $100\\nless than $1000', fontsize = 15)\n",
    "plt.text(x=2.50, y=700, s = 'more than $1000', fontsize = 15)\n",
    "plt.text(x=-0.75, y=-250, s = '     Data Source : The WhiskyExchange | Anirudh Kashyap', fontsize = 12, color = 'black') \n",
    "plt.text(x = -0.75, y = -175,\n",
    "    s = '__________________________________________________________________________________',\n",
    "    color = 'black', alpha = .7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binclass =list(whisky_pd['BinClass'].value_counts().keys())\n",
    "binvalues = list(whisky_pd['BinClass'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE BINARY CLASS DISTRIBUTION\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "boxplot = plt.bar(binclass, binvalues, width = 0.4, align = 'center')\n",
    "plt.xlabel('Price/L in \\$', fontsize = 15, weight = 'bold')\n",
    "plt.ylabel('# of Bottles', fontsize = 15, weight = 'bold')\n",
    "plt.xticks(binclass, size='small')\n",
    "plt.axhline(y = 5, color = 'black', linewidth = 3, alpha = .7)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.text(x=-0.5, y=2000, s = 'Categorizing Whisky prices using Anirudh\\nclassification', fontsize = 20, weight = 'bold')\n",
    "plt.text(x=-0.15, y=1800, s = 'under $500', fontsize = 15)\n",
    "plt.text(x=0.85, y=1100, s = 'more than $500', fontsize = 15)\n",
    "plt.text(x=-0.55, y=-350, s = '     Data Source : The WhiskyExchange | Anirudh Kashyap', fontsize = 12, color = 'black') \n",
    "plt.text(x = -0.55, y = -250,\n",
    "    s = '______________________________________________________________________________',\n",
    "    color = 'black', alpha = .7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelodds = modelpd[['Class 0', 'Class 1', 'Class 2', 'Class 3']].apply(lambda x: np.e**x)\n",
    "modelodds['Factor'] = modelpd['index']\n",
    "modelodds = modelodds[['Factor', 'Class 0', 'Class 1', 'Class 2', 'Class 3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## THIS CELL BLOCK IS VERY VERSATILE CHANGE USING NOTES BELOW TO SORT INFO\n",
    "\n",
    "modelodds = modelodds.sort_values('Class 3', ascending=False).reset_index(drop = True)\n",
    "\n",
    "modelodds = modelodds[~modelodds['Factor'].str.contains('_')]\n",
    "\n",
    "modelodds.head(15)\n",
    "bars = tuple(modelodds['Factor'].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE CLASSIFICATION ODDS DISTRIBUTION\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "bars = tuple(modelodds['Factor'].head(15))\n",
    "y_pos = np.arange(len(bars))\n",
    "odds_number = list(modelodds['Class 3'].head(15))\n",
    "\n",
    "\n",
    "barplot = plt.bar(y_pos, odds_number, color = 'darkgreen', alpha = 0.85)\n",
    "plt.xlabel('Factors', fontsize = 15, weight = 'bold')\n",
    "plt.ylabel('Odd times as likely', fontsize = 15, weight = 'bold')\n",
    "plt.xticks(y_pos, bars, rotation=90)\n",
    "# plt.axhline(y = 0, color = 'black', linewidth = 3, alpha = .7)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "plt.text(x=-0.5, y=3.25, s = 'Analyzing the factors that place whisky in class 3', fontsize = 20, weight = 'bold')\n",
    "plt.text(x=-0.5, y=2.95, s = 'To read the chart: Whisky is (y-value) times as likely to be in class 3 (>$1000)\\nif it contains (x-value)', fontsize = 15)\n",
    "plt.text(x=-2, y=-2.0, s = 'Data Source : The WhiskyExchange | Anirudh Kashyap', fontsize = 12, color = 'black') \n",
    "plt.text(x = -2, y = -1.75, s = '___________________________________________________________________________________________________________'\n",
    "         ,color = 'black', alpha = .7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
